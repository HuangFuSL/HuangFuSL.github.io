{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 决策树\n",
    "\n",
    "决策树是一类基于规则的机器学习算法\n",
    "\n",
    "## 划分指标\n",
    "\n",
    "决策树算法中的核心是每一步划分过程中属性的选择，每一步划分需要取得最大的划分效果，即产生的子集“纯度”最高。常见的三种衡量集合“纯度”的指标为信息增益、增益率与基尼指数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import typing as T"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下考虑西瓜数据集3.0中第一步划分的属性选择。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/melon3.0a.csv')\n",
    "attributes = ['色泽', '根蒂', '敲声', '纹理', '脐部', '触感']\n",
    "category = '好瓜'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "信息增益基于信息熵，在每一次划分后，集合的信息熵之和（按比例加权）会减小信息增益即为原信息熵与划分后的信息熵之差。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>色泽</th>\n",
       "      <th>根蒂</th>\n",
       "      <th>敲声</th>\n",
       "      <th>纹理</th>\n",
       "      <th>脐部</th>\n",
       "      <th>触感</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>信息增益</th>\n",
       "      <td>0.108125</td>\n",
       "      <td>0.142675</td>\n",
       "      <td>0.140781</td>\n",
       "      <td>0.380592</td>\n",
       "      <td>0.289159</td>\n",
       "      <td>0.006046</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            色泽        根蒂        敲声        纹理        脐部        触感\n",
       "信息增益  0.108125  0.142675  0.140781  0.380592  0.289159  0.006046"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def entropy(df, target_col):\n",
    "    p = df[target_col].value_counts() / len(df)\n",
    "    return -sum(p * np.log2(p))\n",
    "\n",
    "def conditional_entropy(df, discrete_col, target_col):\n",
    "    ret = 0\n",
    "    for val in df[discrete_col].unique():\n",
    "        p = len(df[df[discrete_col] == val]) / len(df) # 比例\n",
    "        ret += p * entropy(df[df[discrete_col] == val], target_col)\n",
    "    return ret\n",
    "\n",
    "def calc_gain(df, attributes, category) -> T.Dict[str, float]:\n",
    "    entropy_original = entropy(df, category)\n",
    "    return {\n",
    "        k: entropy_original - conditional_entropy(df, k, category)\n",
    "        for k in attributes\n",
    "    }\n",
    "\n",
    "gain = pd.DataFrame([calc_gain(df, attributes, category)], index=['信息增益'])\n",
    "gain"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "信息增益会更加倾向于选择包含类别更多的属性，使用增益率指标可以平衡不同类别之间的权重。增益率指标为信息增益与属性固有值 $\\mathrm{IV}$ 之比。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>色泽</th>\n",
       "      <th>根蒂</th>\n",
       "      <th>敲声</th>\n",
       "      <th>纹理</th>\n",
       "      <th>脐部</th>\n",
       "      <th>触感</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>增益率</th>\n",
       "      <td>0.06844</td>\n",
       "      <td>0.101759</td>\n",
       "      <td>0.105627</td>\n",
       "      <td>0.263085</td>\n",
       "      <td>0.186727</td>\n",
       "      <td>0.006918</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          色泽        根蒂        敲声        纹理        脐部        触感\n",
       "增益率  0.06844  0.101759  0.105627  0.263085  0.186727  0.006918"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def iv(df, discrete_col):\n",
    "    p = df[discrete_col].value_counts() / len(df)\n",
    "    return -sum(p * np.log2(p))\n",
    "\n",
    "def calc_gain_ratio(df, attributes, category) -> T.Dict[str, float]:\n",
    "    entropy_original = entropy(df, category)\n",
    "    return {k: (entropy_original - conditional_entropy(df, k, category)) / iv(df, k)\n",
    "        for k in attributes\n",
    "    }\n",
    "\n",
    "gain_ratio = pd.DataFrame(\n",
    "    [calc_gain_ratio(df, attributes, category)], index=['增益率']\n",
    ")\n",
    "gain_ratio"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "基尼指数衡量从数据集中随机抽取两个元素，标签取值不同的概率。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>色泽</th>\n",
       "      <th>根蒂</th>\n",
       "      <th>敲声</th>\n",
       "      <th>纹理</th>\n",
       "      <th>脐部</th>\n",
       "      <th>触感</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>基尼指数</th>\n",
       "      <td>0.427451</td>\n",
       "      <td>0.422269</td>\n",
       "      <td>0.423529</td>\n",
       "      <td>0.277124</td>\n",
       "      <td>0.344538</td>\n",
       "      <td>0.494118</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            色泽        根蒂        敲声        纹理        脐部        触感\n",
       "基尼指数  0.427451  0.422269  0.423529  0.277124  0.344538  0.494118"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gini(df, target_col):\n",
    "    p = df[target_col].value_counts() / len(df)\n",
    "    return 1 - sum(p ** 2)\n",
    "\n",
    "def gini_conditional(df, discrete_col, target_col):\n",
    "    ret = 0\n",
    "    for col in df[discrete_col].unique():\n",
    "        p = len(df[df[discrete_col] == col]) / len(df)\n",
    "        ret += p * gini(df[df[discrete_col] == col], target_col)\n",
    "    return ret\n",
    "\n",
    "def calc_gini_index(df, attributes, category) -> T.Dict[str, float]:\n",
    "    return {\n",
    "        k: sum((df[k].value_counts() / len(df)) * gini_conditional(df, k, category))\n",
    "        for k in attributes\n",
    "    }\n",
    "\n",
    "gini_index = pd.DataFrame([calc_gini_index(df, attributes, category)], index=['基尼指数'])\n",
    "gini_index"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 决策树构建\n",
    "\n",
    "本节实现原书图4.2的决策树学习算法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TreeNode():\n",
    "\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "        self.mapping = {}\n",
    "\n",
    "    def add_child(self, value, child):\n",
    "        self.mapping[value] = child\n",
    "\n",
    "    def predict(self, x):\n",
    "        if self.key not in x or x[self.key] not in self.mapping:\n",
    "            return None\n",
    "        if isinstance(self.mapping[x[self.key]], TreeNode):\n",
    "            return self.mapping[x[self.key]].predict(x)\n",
    "        return self.mapping[x[self.key]]\n",
    "\n",
    "def build_tree(df, attributes, category):\n",
    "    if len(df[category].unique()) == 1:\n",
    "        return df[category].unique()[0]\n",
    "    if len(attributes) == 0:\n",
    "        return df[category].value_counts().index[0]\n",
    "    gain = calc_gain(df, attributes, category)\n",
    "    best_attr = max(gain, key=lambda _: gain[_])\n",
    "    for attr in attributes:\n",
    "        if entropy(df, category) - conditional_entropy(df, attr, category) > entropy(df, category) - conditional_entropy(df, best_attr, category):\n",
    "            best_attr = attr\n",
    "    tree = TreeNode(best_attr)\n",
    "    for value in df[best_attr].unique():\n",
    "        tree.add_child(value, build_tree(df[df[best_attr] == value], [attr for attr in attributes if attr != best_attr], category))\n",
    "    return tree\n",
    "\n",
    "tree = build_tree(df, attributes, category)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "决策树采取自顶向下的predict方式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'是'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assert isinstance(tree, TreeNode)\n",
    "tree.predict({\n",
    "    '色泽': '青绿',\n",
    "    '根蒂': '蜷缩',\n",
    "    '敲声': '浊响',\n",
    "    '纹理': '清晰',\n",
    "    '脐部': '凹陷',\n",
    "    '触感': '硬滑'\n",
    "})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 决策树剪枝处理\n",
    "\n",
    "决策树有预剪枝和后剪枝两个剪枝步骤，剪枝可以缓解模型出现的过拟合现象。\n",
    "\n",
    "### 预剪枝\n",
    "\n",
    "预剪枝在模型的训练阶段就通过验证集的准确性来决定是否进行划分。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "剪枝前: 4, 剪枝后: 4\n",
      "剪枝\n",
      "剪枝前: 5, 剪枝后: 0\n",
      "不剪枝\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4444444444444444"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def no_split(train, test, attributes, category):\n",
    "    return train[category].value_counts().index[0]\n",
    "\n",
    "def build_pre_prune(train, test, attributes, category, tree_root=None):\n",
    "    if len(train[category].unique()) == 1:\n",
    "        return train[category].unique()[0]\n",
    "    no_split_result = no_split(train, test, attributes, category)\n",
    "    no_split_metric = np.sum(test[category] == no_split_result)\n",
    "    if len(attributes) == 0:\n",
    "        return no_split_result\n",
    "\n",
    "    # 选择划分属性\n",
    "    gain = calc_gain(train, attributes, category)\n",
    "    best_attr = max(gain, key=lambda _: gain[_])\n",
    "\n",
    "    # 创建节点\n",
    "    tree = TreeNode(best_attr)\n",
    "    if tree_root is None:\n",
    "        tree_root = tree\n",
    "    for value in train[best_attr].unique():\n",
    "        tree.add_child(value, no_split(\n",
    "            train[train[best_attr] == value], test,\n",
    "            [attr for attr in attributes if attr != best_attr], category\n",
    "        ))\n",
    "\n",
    "    # 计算剪枝效果\n",
    "    result = []\n",
    "    for row in test[attributes].itertuples():\n",
    "        row_dict = row._asdict()\n",
    "        result.append(tree_root.predict(row_dict))\n",
    "    split_metric = np.sum([a == b for a, b in zip(result, test[category])])\n",
    "\n",
    "    # 剪枝\n",
    "    print(f'剪枝前: {no_split_metric}, 剪枝后: {split_metric}')\n",
    "    if split_metric < no_split_metric:\n",
    "        print('不剪枝')\n",
    "        return no_split_result\n",
    "    print('剪枝')\n",
    "    for value in train[best_attr].unique():\n",
    "        child = build_pre_prune(\n",
    "            train[train[best_attr] == value], test,\n",
    "            [attr for attr in attributes if attr != best_attr], category,\n",
    "            tree_root\n",
    "        )\n",
    "        tree.add_child(value, child)\n",
    "    return tree\n",
    "\n",
    "train, test = train_test_split(df, test_size=0.5)\n",
    "tree = build_pre_prune(train, test, attributes, category)\n",
    "\n",
    "result = [\n",
    "    tree.predict(row._asdict()) if isinstance(tree, TreeNode) else tree\n",
    "    for row in test[attributes].itertuples()\n",
    "]\n",
    "split_metric = np.mean([a == b for a, b in zip(result, test[category])])\n",
    "split_metric"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 后剪枝\n",
    "\n",
    "后剪枝在决策树生成后再遍历决策树，删去过多的节点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_post_prune(train, test, attributes, category):\n",
    "    tree = build_tree(train, attributes, category)\n",
    "    # TODO: apply post pruning"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
